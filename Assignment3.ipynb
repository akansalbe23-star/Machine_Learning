{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da24b68a",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ab28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91959937",
   "metadata": {},
   "source": [
    "### Step a: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9132be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"D:/Courses/Machine Learning/Class Assignment/USA_Housing.csv\")\n",
    "X = df.drop(\"Price\", axis=1).values\n",
    "y = df[\"Price\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2ef91",
   "metadata": {},
   "source": [
    "### Step b: Scale the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b1d4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()     \n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44114f91",
   "metadata": {},
   "source": [
    "### Step c: 5-fold cross-validation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29bf0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_beta = None\n",
    "best_r2 = -np.inf    \n",
    "r2_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882fde3",
   "metadata": {},
   "source": [
    "### Step d: Perform 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05f805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: R2 Score = 0.9180\n",
      "Fold 2: R2 Score = 0.9146\n",
      "Fold 3: R2 Score = 0.9116\n",
      "Fold 4: R2 Score = 0.9193\n",
      "Fold 5: R2 Score = 0.9244\n",
      "\n",
      "Average R2 Score across 5 folds: 0.9175745431092714\n",
      "Best R2 Score: 0.9243869413350316\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled)):      #kf.split(X_scaled) generates 5 splits (since we used KFold(n_splits=5)).\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Add bias column of ones for intercept\n",
    "    X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "    # Compute beta using Least Squares: β = (XᵀX)^(-1) Xᵀy\n",
    "    beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ (X_train_bias.T @ y_train)\n",
    "     # Predictions\n",
    "    y_pred = X_test_bias @ beta\n",
    "\n",
    "    # R2 score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    print(f\"Fold {fold+1}: R2 Score = {r2:.4f}\")\n",
    "\n",
    "    # Track best beta\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_beta = beta\n",
    "\n",
    "print(\"\\nAverage R2 Score across 5 folds:\", np.mean(r2_scores))\n",
    "print(\"Best R2 Score:\", best_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae73ee",
   "metadata": {},
   "source": [
    "#### Step e: Train on 70% using best beta and test on 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "530e7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance using Best Beta:\n",
      "Train R2 Score: 0.9193\n",
      "Test R2 Score: 0.9147\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "# Train using best beta on 70% data\n",
    "y_train_pred = X_train_bias @ best_beta\n",
    "y_test_pred = X_test_bias @ best_beta\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nFinal Model Performance using Best Beta:\")\n",
    "print(f\"Train R2 Score: {train_r2:.4f}\")\n",
    "print(f\"Test R2 Score: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86bc682",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b0a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- R² Scores for Different Learning Rates ---\n",
      "Learning Rate = 0.001 | Validation R² = 0.9195 | Test R² = 0.9135\n",
      "Learning Rate = 0.01 | Validation R² = 0.9161 | Test R² = 0.9105\n",
      "Learning Rate = 0.1 | Validation R² = 0.9058 | Test R² = 0.8993\n",
      "Learning Rate = 1 | Validation R² = -89112476993756.3906 | Test R² = -85051867046715.2500\n",
      "\n",
      "Best Learning Rate: 0.001\n",
      "Best Validation R²: 0.9195\n",
      "Test R² (with best model): 0.9135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"USA_Housing.csv\")\n",
    "X = df.drop(\"Price\", axis=1).values\n",
    "y = df[\"Price\"].values\n",
    "\n",
    "# Split dataset (56% train, 14% validation, 30% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.44, random_state=42\n",
    ")\n",
    "\n",
    "# Now split temp into validation (14%) and test (30%)\n",
    "val_size = 14 / (14 + 30)  # proportion of validation in remaining 44%\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=1 - val_size, random_state=42\n",
    ")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train with different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = SGDRegressor(\n",
    "        learning_rate=\"constant\", eta0=lr, max_iter=1000, tol=None, random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # R² scores\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results[lr] = (r2_val, r2_test)\n",
    "\n",
    "print(\"\\n--- R² Scores for Different Learning Rates ---\")\n",
    "for lr, (r2_val, r2_test) in results.items():\n",
    "    print(f\"Learning Rate = {lr} | Validation R² = {r2_val:.4f} | Test R² = {r2_test:.4f}\")\n",
    "\n",
    "# Best learning rate based on validation score\n",
    "best_lr = max(results, key=lambda k: results[k][0])\n",
    "print(f\"\\nBest Learning Rate: {best_lr}\")\n",
    "print(f\"Best Validation R²: {results[best_lr][0]:.4f}\")\n",
    "print(f\"Test R² (with best model): {results[best_lr][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6cd85",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0936df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "R2 Score: 0.8044422435762588\n",
      "MSE: 13422229.591732565\n",
      "\n",
      "Linear Regression with PCA Performance:\n",
      "R2 Score: 0.7500675882701553\n",
      "MSE: 17154268.253029242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kansa\\AppData\\Local\\Temp\\ipykernel_23708\\2274744168.py:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"num_doors\"] = df[\"num_doors\"].replace(num_map).astype(\"Int64\")   # nullable integer\n",
      "C:\\Users\\kansa\\AppData\\Local\\Temp\\ipykernel_23708\\2274744168.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"num_cylinders\"] = df[\"num_cylinders\"].replace(num_map).astype(\"Int64\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Load dataset\n",
    "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
    "           \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
    "           \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\",\n",
    "           \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "           \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "df = pd.read_csv(url, names=columns)\n",
    "df\n",
    "# Replace \"?\" with NaN\n",
    "df = df.mask(df == \"?\", np.nan)\n",
    "#df\n",
    "\n",
    "# Step 2: Replace NaN with central tendency (mean for numeric, mode for categorical)\n",
    "for col in df.columns:\n",
    "    # try to treat column as numeric first (safe conversion)\n",
    "    col_num = pd.to_numeric(df[col], errors='coerce')  # non-convertible -> NaN\n",
    "\n",
    "    # if enough values converted to numeric, treat as numeric; otherwise categorical\n",
    "    if col_num.notna().sum() >= (len(df) / 2):   # heuristic: majority numeric\n",
    "        mean_val = col_num.mean()\n",
    "        df[col] = col_num.fillna(mean_val)      # assign back numeric series\n",
    "    else:\n",
    "        # categorical: use mode if available, else leave NaN\n",
    "        modes = df[col].mode(dropna=True)\n",
    "        if not modes.empty:\n",
    "            df[col] = df[col].fillna(modes[0])\n",
    "        else:\n",
    "            df[col] = df[col]  # nothing to do; leave as-is\n",
    "\n",
    "# Drop rows with NaN in price\n",
    "df = df[df[\"price\"].notna()]\n",
    "#df\n",
    "# Step 3: Encoding categorical features\n",
    "# (i) num_doors & num_cylinders: convert text to numbers\n",
    "num_map = {\n",
    "    \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6,\n",
    "    \"eight\": 8, \"twelve\": 12\n",
    "}\n",
    "df[\"num_doors\"] = df[\"num_doors\"].replace(num_map).astype(\"Int64\")   # nullable integer\n",
    "df[\"num_cylinders\"] = df[\"num_cylinders\"].replace(num_map).astype(\"Int64\")\n",
    "\n",
    "# (ii) body_style & drive_wheels: Dummy Encoding\n",
    "df = pd.get_dummies(df, columns=[\"body_style\", \"drive_wheels\"], drop_first=True)\n",
    "\n",
    "# (iii) make, aspiration, engine_location, fuel_type: Label Encoding\n",
    "label_cols = [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# (iv) fuel_system: pfi → 1, else 0\n",
    "df[\"fuel_system\"] = df[\"fuel_system\"].apply(lambda x: 1 if \"pfi\" in x else 0)\n",
    "\n",
    "# (v) engine_type: ohc → 1, else 0\n",
    "df[\"engine_type\"] = df[\"engine_type\"].apply(lambda x: 1 if \"ohc\" in x else 0)\n",
    "\n",
    "# Convert all numeric columns properly\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "# Step 4: Divide features (X) and target (y)\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Scale input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Train/Test split and Linear Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Linear Regression Performance:\")\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Step 6: PCA + Linear Regression\n",
    "pca = PCA(n_components=0.95)  # retain 95% variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
    "    X_pca, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "lr_pca = LinearRegression()\n",
    "lr_pca.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "print(\"\\nLinear Regression with PCA Performance:\")\n",
    "print(\"R2 Score:\", r2_score(y_test_pca, y_pred_pca))\n",
    "print(\"MSE:\", mean_squared_error(y_test_pca, y_pred_pca))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
